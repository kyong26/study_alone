```python
import pandas as pd
import re
import time

# 워드클라우드 생성을 위한 샘플
df = pd.read_excel('/Users/xnsk2/Anaconda3/envs/shomy/toss.xlsx')

# 특수문자 처리하기
df = df[['num','contents']]
df['contents_mod'] = list(map(lambda x: re.sub('[1-9\/:*!?"<>()|&]', '', x), df['contents']))
df['contents_mod'] =df['contents_mod'].str.replace(",", "", regex=False)
df['contents_mod'] =df['contents_mod'].str.replace(".", "", regex=False)
df.head(3)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>num</th>
      <th>contents</th>
      <th>contents_mod</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>넷플릭스 돈을 같이 모으고 싶어용</td>
      <td>넷플릭스 돈을 같이 모으고 싶어용</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>자동이체날짜를 알고 싶어요</td>
      <td>자동이체날짜를 알고 싶어요</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>1.부동산 투자시 상환횟수가 표시되면 좋겠어요 언제쯤 상환예정인지 알수있도록요. 2...</td>
      <td>부동산 투자시 상환횟수가 표시되면 좋겠어요 언제쯤 상환예정인지 알수있도록요 투자수익...</td>
    </tr>
  </tbody>
</table>
</div>




```python
%%time

# Py-Hanspell로 맞춤법+띄어쓰기 교정
from hanspell import spell_checker

df['contents_mod'] = list(map(lambda x:spell_checker.check(x).checked, df['contents_mod']))
df.head(3)
```

    Wall time: 1min 41s
    




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>num</th>
      <th>contents</th>
      <th>contents_mod</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>넷플릭스 돈을 같이 모으고 싶어용</td>
      <td>넷플릭스 돈을 같이 모으고 싶어요</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>자동이체날짜를 알고 싶어요</td>
      <td>자동이체 날짜를 알고 싶어요</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>1.부동산 투자시 상환횟수가 표시되면 좋겠어요 언제쯤 상환예정인지 알수있도록요. 2...</td>
      <td>부동산 투자 시 상환 횟수가 표시되면 좋겠어요 언제쯤 상환 예정인지 알 수 있도록 ...</td>
    </tr>
  </tbody>
</table>
</div>




```python
df[df['contents'].str.contains('ㅠㅠㅠㅠ')]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>num</th>
      <th>contents</th>
      <th>contents_mod</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>194</th>
      <td>198</td>
      <td>토스와 은행의 직접적인 뱅킹은 입출금 내역이 안뜨니 조금 불편한 감이 없이 않아있습...</td>
      <td>토스와 은행의 직접적인 뱅킹은 입출금 내역이 안 뜨니 조금 불편한 감이 없이 않아있...</td>
    </tr>
    <tr>
      <th>651</th>
      <td>2542</td>
      <td>친구가 내 계좌로 돈 보냈는데 안 들어옴ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ</td>
      <td>친구가 내 계좌로 돈 보냈는데 안 들어옴ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ</td>
    </tr>
  </tbody>
</table>
</div>




```python
#비문 문자열 제거
df['contents_mod'] =df['contents_mod'].str.replace("ㅠ", "", regex=False)

#반복되는 문자 정제하기
from soynlp.normalizer import *
df['contents_mod'] = list(map(lambda x:emoticon_normalize(x, num_repeats=2), df['contents_mod']))
```


```python
#결과확인
df[df['contents'].str.contains('ㅠㅠㅠㅠ')]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>num</th>
      <th>contents</th>
      <th>contents_mod</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>194</th>
      <td>198</td>
      <td>토스와 은행의 직접적인 뱅킹은 입출금 내역이 안뜨니 조금 불편한 감이 없이 않아있습...</td>
      <td>토스와 은행의 직접적인 뱅킹은 입출금 내역이 안 뜨니 조금 불편한 감이 없이 않아있...</td>
    </tr>
    <tr>
      <th>651</th>
      <td>2542</td>
      <td>친구가 내 계좌로 돈 보냈는데 안 들어옴ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ</td>
      <td>친구가 내 계좌로 돈 보냈는데 안 들어옴</td>
    </tr>
  </tbody>
</table>
</div>




```python
#불용어 제거하기

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize 
from konlpy.tag import Okt
from ckonlpy.tag import Twitter

tokenizer = Okt()
twitter = Twitter()

twitter.add_dictionary('금융사', 'Noun')

#불용어사전: https://www.ranks.nl/stopwords/korean
#파일 인코딩을 ANSI로 설정해야 잘 읽힌다.
stop_words = set(line.strip() for line in open('/users/xnsk2/Downloads/txt_sample.txt'))

#불용어 추가하기
stop_words = stop_words | set(['싶어요','좋겠어요','좋겠습니다','인해서','시','수'])

#토큰화(특정 품사만 남기기)+불용어 반영하기
def tokenization(x):
    word_tokens = []
    for word in tokenizer.pos(x, stem=True):
        if word[1] in ['Noun', 'Verb', 'Adjective']: #명사, 동사, 형용사
            if len( word[1])>1:
                word_tokens.append(word[0])
    result = [word for word in word_tokens if not word in stop_words]
    return result

#적용
df['token'] = list(map(tokenization, df['contents_mod']))

words_all = []
for i in range(len(df)):
    for j in range(len(df['token'][i])):
        words_all.append(df['token'][i][j])
```

    C:\Users\xnsk2\Anaconda3\envs\shomy\lib\site-packages\konlpy\tag\_okt.py:17: UserWarning: "Twitter" has changed to "Okt" since KoNLPy v0.4.5.
      warn('"Twitter" has changed to "Okt" since KoNLPy v0.4.5.')
    


```python
#결과확인
df[['contents_mod','token']][:10]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>contents_mod</th>
      <th>token</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>넷플릭스 돈을 같이 모으고 싶어요</td>
      <td>[넷플릭스, 돈, 모으다, 싶다]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>자동이체 날짜를 알고 싶어요</td>
      <td>[자동, 이체, 날짜, 알, 싶다]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>부동산 투자 시 상환 횟수가 표시되면 좋겠어요 언제쯤 상환 예정인지 알 수 있도록 ...</td>
      <td>[부동산, 투자, 상환, 횟수, 표시, 되다, 좋다, 상환, 예정, 알, 요, 투자...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>가계부 수입에 비해 지출 초과분을 미리 알려줘서 과소비 방지를 해줬으면 좋겠습니다</td>
      <td>[가계부, 수입, 비다, 지출, 초과, 미리, 알다, 소비, 방지, 해주다, 좋다]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>가계부 추출 기능 통신사별 멤버십 혜택이 가능한 장소 정보 접근성 향상에 관련 금융...</td>
      <td>[가계부, 추출, 기능, 통신, 사별, 멤버십, 혜택, 가능하다, 장소, 정보, 접...</td>
    </tr>
    <tr>
      <th>5</th>
      <td>각 카드별로 내가 혜택을 잘 받고 있는지 관리하고 확인이 가능하면 좋겠다 실적을 채...</td>
      <td>[카드, 별로, 내, 혜택, 자다, 받다, 관리, 확인, 가능하다, 좋다, 실적, ...</td>
    </tr>
    <tr>
      <th>6</th>
      <td>각종 금융사별 카드 내역을 다 종합해서 내가 어느 카테고리에서 썼는지 쉽게 볼 수 ...</td>
      <td>[금융, 사별, 카드, 역, 종합, 하다, 내, 카테고리, 써다, 쉬다, 볼]</td>
    </tr>
    <tr>
      <th>7</th>
      <td>각종 브랜드별 생일 축하 쿠폰이나 기념일 혜택을 찾아주면 좋겠어요 하나도 못 누리고 있음</td>
      <td>[브랜드, 별, 생일, 축하, 쿠폰, 기념일, 혜택, 찾다, 좋다, 못, 누리]</td>
    </tr>
    <tr>
      <th>8</th>
      <td>각종 포인트들 전부 제각각 흩어져있고 대체 어떤 포인트를 어디서 봐야 하는지 얼마나...</td>
      <td>[포인트, 제각각, 흩어지다, 대체, 어떻다, 포인트, 보다, 하다, 쌓이다, 알,...</td>
    </tr>
    <tr>
      <th>9</th>
      <td>간편송금의 장점으로 인해서 주거래은행 어플보다 토스 이용을 하는 편이지만 타행들도 ...</td>
      <td>[간편, 송금, 장점, 인하다, 거래, 은행, 어플, 토스, 이용, 하다, 편이, ...</td>
    </tr>
  </tbody>
</table>
</div>




```python
#쪼개진 단어들이 몇 번 언급되었는지 확인하기

from collections import Counter
count = Counter(words_all)
rank_text = count.most_common() #내림차순 정렬
```


```python
rank_text = dict(rank_text)
temp_dic = {}
for key, value in rank_text.items():
    if value>=10 and len(key)>1: #30번 초과, 한글자이상
        temp_dic[key] = value
rank_text = temp_dic
```


```python
#불용어 추가하기
add_stop_words = ['하다','되다','이다','않다','돼다','싶다','좋다'] #좋다: "좋겠어요"가 대부분임
stop_words = stop_words | set(add_stop_words)

temp_dic = {}
for key, value in rank_text.items():
    if key not in stop_words:
        temp_dic[key] = value
```


```python
#워드클라우드 그리기
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image

font_path = '/Users/xnsk2/Downloads/SpoqaHanSansNeo_all/SpoqaHanSansNeo_all/SpoqaHanSansNeo_TTF_original/SpoqaHanSansNeo-Medium.ttf'
wordcolud = WordCloud(font_path = font_path, 
                      colormap='PuBu',
                      width=480, height=480,
                      background_color='white',
                     )
wc = wordcolud.generate_from_frequencies(temp_dic)

plt.figure(figsize=(8,15))
plt.imshow(wc)
plt.imshow(wc, interpolation='bilinear')
plt.axis("off")
plt.show()
```

![image](https://user-images.githubusercontent.com/52664532/165288858-5690ab85-490f-41cf-be6b-f7d113114d41.png)

    



```python
#주요 키워드 포함한 데이터 확인
df[df.contents_mod.str.contains('카드')][:3]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>num</th>
      <th>contents</th>
      <th>contents_mod</th>
      <th>token</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>8</td>
      <td>각 카드별로 내가 혜택을 잘 받고 있는지 관리하고 확인이 가능하면 좋겠다. 실적을 ...</td>
      <td>각 카드별로 내가 혜택을 잘 받고 있는지 관리하고 확인이 가능하면 좋겠다 실적을 채...</td>
      <td>[카드, 별로, 내, 혜택, 자다, 받다, 관리, 확인, 가능하다, 좋다, 실적, ...</td>
    </tr>
    <tr>
      <th>6</th>
      <td>9</td>
      <td>각종 금융사별 카드 내역을 다 종합해서, 내가 어느 카테고리에서 썻는지 쉽게 볼수있었으면</td>
      <td>각종 금융사별 카드 내역을 다 종합해서 내가 어느 카테고리에서 썼는지 쉽게 볼 수 ...</td>
      <td>[금융, 사별, 카드, 역, 종합, 하다, 내, 카테고리, 써다, 쉬다, 볼]</td>
    </tr>
    <tr>
      <th>10</th>
      <td>13</td>
      <td>결제할때마다, 내가 가진 카드들 중에 어떤 카드로 결제하면 할인을 받을 수 있는지 ...</td>
      <td>결제할 때마다 내가 가진 카드들 중에 어떤 카드로 결제하면 할인을 받을 수 있는지 ...</td>
      <td>[결제, 하다, 내, 가지다, 카드, 중, 어떻다, 카드, 결제, 하다, 할인, 받...</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 추가: 유사한 단어 찾기
from gensim.models.word2vec import Word2Vec

model = Word2Vec(df['token'], sg=1, window=2, min_count=3)
```


```python
#단어 두 개 유사도 파악
model.wv.similarity('카드', '인증서')
```




    0.97803724




```python
model.wv.most_similar("카드", topn=5)
```




    [('나가다', 0.997490644454956),
     ('볼', 0.9966548681259155),
     ('자다', 0.9966009259223938),
     ('포인트', 0.996548593044281),
     ('안', 0.9964513778686523)]




```python
similarity_dict = {} 

for key1, value1 in temp_dic.items():
    word_list = []
    for key2, value2 in model.wv.most_similar(temp_dic[key1], topn=5):
        word_list.append(key2)
    similarity_dict[key1] = word_list
```
